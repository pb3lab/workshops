{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyMwBDu5RVbHNovHiqE5nGmM"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Tutorial 03 – Metagenomic data processing: from reads to protein functions"],"metadata":{"id":"khNYDMVIMD0T"}},{"cell_type":"markdown","source":["## Overview"],"metadata":{"id":"FZqcPx1qM4QQ"}},{"cell_type":"markdown","source":["In this tutorial, we will start with the process of downloading a small metagenome from the NCBI database, on which we will perform different analyses.\n","\n","The structure of the directories in which the work will be distributed is as follows, separating the different steps of the data processing into different folders:\n","\n","```\n","- /SRR2239652/\n","  - /01_raw_reads/\n","  - /02_clean_reads/\n","  - /03_assembly_msp/\n","  - /04_binning_mW/\n","  - /05_binref_mW/\n","  - /06_MAGs_refinement1\n","  - /07_metaprodigal\n","  - /08_quantify\n","  - /09_metabolic\n","```"],"metadata":{"id":"Ot-96eBaM7Sk"}},{"cell_type":"markdown","source":["#Part 0. Downloading and Installing the required software"],"metadata":{"id":"w42u_lDwNuTc"}},{"cell_type":"markdown","source":["Before we start, you must first **remember to start the hosted runtime in Google Colab**.\n","\n","Then, we must install several pieces of software to perform this tutorial. Namely:\n","- **SRA Toolkit** for manipulating SRA accession IDs from the SRA database.\n","- **mambaforge**, a free minimal installer and re-implementation of **conda** for software package and environment management.\n","- **fastqc**, a tool to assess the quality of the sequencing data.\n","- **cutadapt**, a tool for trimming the adapter sequences and other types of unwanted sequences from the data.\n","- **SPAdes**, a genome and metagenome assembly toolkit containing various assembly pipelines.\n","- **prodigal**, a protein-coding gene prediction tool for prokaryotic genomes.\n","- **CoverM**, a DNA read coverage and relative abundance calculator focused on metagenomics applications.\n","- **MetaWRAP**, an easy-to-use metagenomic wrapper suite that accomplishes the core tasks of metagenomic analysis from start to finish.\n","- **metabolic**, a tool for high-throughput profiling of genomes from isolates, metagenome-assembled genomes, or single-cell genomes\n","\n","\n","\n","### ⚠️ **WARNING**: This installation process is particularly long, and can require up to 30 min. Please proceed with the installation with sufficient anticipation before the actual tutorial starts."],"metadata":{"id":"z5LSns9LNviU"}},{"cell_type":"markdown","source":["After several tests, the following installation instructions are the best way of setting up **Google Colab** for this laboratory session.\n","\n","1. Install **SRA toolkit** from pre-compiled Ubuntu libraries and test that it is correctly installed."],"metadata":{"id":"RA5FfQ7TPmvU"}},{"cell_type":"code","source":["%%bash\n","#Downloading the latest pre-compiled version of SRA Toolkit (now, v3.0.0)\n","wget --quiet --output-document sratoolkit.tar.gz https://ftp-trace.ncbi.nlm.nih.gov/sra/sdk/current/sratoolkit.current-ubuntu64.tar.gz\n","tar -xzf sratoolkit.tar.gz"],"metadata":{"id":"TU4EnhVBiN9C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%bash\n","#Setting up SRA Toolkit and testing that it is correctly installed\n","#On Google Colab, this PATH export will be required in every code cell to execute SRA Toolkit\n","export PATH=$PATH:/content/sratoolkit.3.0.0-ubuntu64/bin\n","#Setting up\n","echo \"Aexyo\" | vdb-config -i\n","#Test, which should print sequence data\n","fastq-dump --stdout -X 2 SRR390728"],"metadata":{"id":"2ReJONcv_qc3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["2. Install **mamba** using **condacolab**, which will enable the installation of **fastqc, cutadapt, SPAdes, prodigal, and CoverM**"],"metadata":{"id":"v3GJ_6cVPUlW"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"gvS2iybY0yKh"},"outputs":[],"source":["#Installing Conda using Condacolab\n","!pip install -q condacolab\n","import condacolab\n","condacolab.install_mambaforge()"]},{"cell_type":"code","source":["%%bash\n","#Installing fastqc, cutadapt, prodigal, and coverm using conda\n","mamba install -y -c bioconda fastqc cutadapt prodigal coverm spades"],"metadata":{"id":"WOioYCJXcYk7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["3. Install **MetaWRAP** on a new conda environment using **mamba**"],"metadata":{"id":"PK6_Wv7qQdN4"}},{"cell_type":"code","source":["%%bash\n","#Installing MetaWRAP on a different conda environment that we will need to\n","#summon everytime we want to use it\n","conda config --add channels defaults\n","conda config --add channels conda-forge\n","conda config --add channels bioconda\n","conda config --add channels ursky\n","mamba create -y --name mwrap-env --channel ursky metawrap-mg=1.3.2 spades"],"metadata":{"id":"uUw40G8_wkcE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["4. Configure the **CheckM** database for properly running metaWRAP"],"metadata":{"id":"VHN_d2IXQmCs"}},{"cell_type":"code","source":["#Downloading the CheckM database on a user-specified folder\n","%cd /content/\n","!mkdir checkm_folder\n","# Now download using wget\n","%cd checkm_folder\n","!wget --quiet https://data.ace.uq.edu.au/public/CheckM_databases/checkm_data_2015_01_16.tar.gz\n","!tar -xzf *.tar.gz\n","!rm *.gz\n","%cd ../"],"metadata":{"id":"R0P26NFPiTdt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%bash\n","#Now we will activate our conda environment for metaWRAP\n","source activate mwrap-env\n","#Configuring the CheckM database\n","echo \"/content/checkm_folder/\" > option\n","echo \" \" >> option\n","# On newer versions of CheckM, you would run:\n","checkm data setRoot < option\n","checkm data setRoot < option"],"metadata":{"id":"jyyKz6VaivGe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["4. Install **metabolic** and its metabolic profiles on a new conda environment using **mamba**"],"metadata":{"id":"UCwULtLFRe_v"}},{"cell_type":"code","source":["%%bash\n","#Installing metabolic on a on a different conda environment that we will need to\n","#summon everytime we want to use it\n","mamba create -y --name metabolic-env -c hcc metabolic"],"metadata":{"id":"38Lb2gK8wa3N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%time\n","%%bash\n","#Now we will activate our conda environment for metabolic\n","source activate metabolic-env\n","#Downloading the metabolic profiles\n","download-metabolic-profiles.sh"],"metadata":{"id":"9-VrVoltyhkK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Part I - Quality control and trimming of the reads in a SRA file"],"metadata":{"id":"ZPvaw7z7WHLX"}},{"cell_type":"markdown","source":["1. The metagenome will be directly downloaded from the NCBI SRA database with the **fastq-dump** software from **SRA toolkit** and splitting the files into forward (\\*_1.fastq) and reverse (\\*_2.fastq) files."],"metadata":{"id":"ODgcpkj2WZtU"}},{"cell_type":"code","source":["#We will work on metagenomic sequencing data from SRA accession ID\n","#We set up this accession ID as a python variable here\n","SRA='SRR2239652'\n","#This is how we create a folder with mkdir: mkdir NAME\n","!mkdir {SRA}\n","#We now enter the new folder permanently (with magic command %) and download our SRA file using wget\n","%cd {SRA}\n","!mkdir 01_raw_reads\n","%cd 01_raw_reads\n","!wget --quiet https://sra-pub-run-odp.s3.amazonaws.com/sra/{SRA}/{SRA}"],"metadata":{"id":"nd1roCRjlxay"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%time\n","%%bash\n","#Now we will process our downloaded SRA file with fastq-dump\n","#On Google Colab, this PATH export will be required in every code cell to execute SRA Toolkit\n","export PATH=$PATH:/content/sratoolkit.3.0.0-ubuntu64/bin\n","#We set up our SRA accession ID as a variable\n","SRA=SRR2239652\n","#Now we will process our downloaded SRA file with fastq-dump\n","fastq-dump --split-files $SRA"],"metadata":{"id":"RxhppSh-m0QL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["2. Quality along the reads is provided with the **fastqc** software before and after the trimming process. "],"metadata":{"id":"X491Wh9CWkhS"}},{"cell_type":"code","source":["%%time\n","%%bash\n","#Now we will process our FW and RV fastq files with fastqc\n","export PATH=$PATH:/content/sratoolkit.3.0.0-ubuntu64/bin\n","fastqc SRR2239652_1.fastq SRR2239652_2.fastq\n","#Now we will check the quality control (QC) curves\n","#Download the fastqc-generated html files and manually inspect them"],"metadata":{"id":"fAizyTmLnjAb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@markdown ### 1. Load HTML file from fastqc\n","html_filename = \"/content/SRR2239652/01_raw_reads/SRR2239652_1_fastqc.html\" #@param {type:\"string\"}\n","#@markdown - This script assumes the HTML file is located in the current folder\n","\n","print('\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n')\n","import IPython\n","IPython.display.HTML(filename=html_filename)"],"metadata":{"cellView":"form","id":"BDeUosjJJSbs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["3. With the fastqc curves, it can be determined which sequence segments parts of the reads should be trimmed. The **cutadapt** software will remove the reads with the following parameters\n","  - average phred quality value below 28 (`-q 28`)\n","  - the first and last 15 bp of the forward reads (`-U 15 -U -15`) \n","  - the first 20 and last 15 bp from the reverse reads (`-u 20 -u -15`).\n","  - remove the reads shorter than 50 bp (`-m 50`) and with any undetermined base (N) (`--trim-n --max-n 1`)."],"metadata":{"id":"mO2O-SYnWvcu"}},{"cell_type":"code","source":["#We will create a new directory in which we will run the next step of the tutorial\n","%cd ..\n","%mkdir 02_clean_reads\n","%cd 02_clean_reads"],"metadata":{"id":"rf3S2knQH3-H"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%time\n","%%bash\n","#Now, we will run cutadapt to trim the adapters based on parameters derived\n","#from the QC curves and then run again our QC using fastqc\n","export PATH=$PATH:/content/sratoolkit.3.0.0-ubuntu64/bin\n","#We set up this accession ID as a variable\n","SRA=SRR2239652\n","#Here is an example of our cutadapt run and parameters\n","cutadapt -q 28 -U 15 -U -15 -u 20 -u -15 -m 50 --trim-n --max-n 1 -o t$SRA\\_1.fastq -p t$SRA\\_2.fastq ../01_raw_reads/$SRA\\_1.fastq  ../01_raw_reads/$SRA\\_2.fastq\n","#Running fastqc on our trimmed fastq files\n","fastqc t$SRA\\_1.fastq t$SRA\\_2.fastq"],"metadata":{"id":"HBrjYIQ4IISy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Part II - Assembling our metagenomes using metaWRAP"],"metadata":{"id":"Rdlt93GgWiGN"}},{"cell_type":"markdown","source":["1. After checking the clean reads, the conda environment of the metaWRAP software package and its several tools will be used.\n","\n","  A metagenome assembly will be done with the software **SPAdes** in the metagenomics (`--meta`) mode. Other options can be, for example, `--carefull` for genomes from isolates instead.\n","  It is recommended to use the highest number of threads (here 2 CPUs, `-t 2`) as well as RAM memory (here 8 GB, `-m 8`) for this process. If the process needs more memory, it will **stop**. "],"metadata":{"id":"SV7UdBX3WmuB"}},{"cell_type":"markdown","source":["### ⚠️ **CAUTION**: The following script takes 1h and 30 min on Google Colab due to its low number of CPUs (only 2). For continuation of the tutorial, we will downloaded a pre-assembled file instead"],"metadata":{"id":"58rR_tHxaZJV"}},{"cell_type":"code","source":["#We will now exit our previous folder and create a new one for our next steps\n","#%cd ..\n","%mkdir 03_assembly_msp\n","%cd 03_assembly_msp"],"metadata":{"id":"3g3KYAJuK2kn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1665413530125,"user_tz":180,"elapsed":24,"user":{"displayName":"CESAR ANTONIO RAMIREZ SARMIENTO","userId":"14747634753705802785"}},"outputId":"481fc307-5884-4d04-f593-2d1aa9197124"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/03_assembly_msp\n"]}]},{"cell_type":"code","source":["#Downloading the pre-assembled files from a previous SPAdes run\n","!wget https://raw.githubusercontent.com/pb3lab/workshops/main/backups/saocarlos2022/contigs.fasta\n","!wget https://raw.githubusercontent.com/pb3lab/workshops/main/backups/saocarlos2022/spades.log"],"metadata":{"id":"jPqVq9sXX0FG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","\n","```\n","#COPY THIS SCRIPT INTO A CODE CELL ONLY IF YOU HAVE 2 H OF FREE TIME TO PATIENTLY WORK ON THIS\n","%%time\n","%%bash\n","#Now we will activate our conda environment for metaWRAP\n","source activate mwrap-env\n","#We set up this accession ID as a variable\n","SRA=SRR2239652\n","#We will assembly the trimmed reads using SPAdes with 2 threads and 8 GB RAM\n","#This is sub-optimal, due to Google Colab limitations\n","spades.py --meta -t 2 -m 8 -1 ../02_clean_reads/t$SRA\\_1.fastq -2 ../02_clean_reads/t$SRA\\_2.fastq -o .\n","```\n","\n"],"metadata":{"id":"pCahk4slYiqV"}},{"cell_type":"markdown","source":["2. The stats of the assembly can be seen with the **quast** software, which will give the main stats of the obtained contigs like numbers and sizes."],"metadata":{"id":"Zz38MKkqYe5x"}},{"cell_type":"code","source":["%%time\n","%%bash\n","#Now we will activate our conda environment for metaWRAP\n","source activate mwrap-env\n","#We set up this accession ID as a variable\n","SRA=SRR2239652\n","#Analyze using quast\n","quast contigs.fasta"],"metadata":{"id":"s-0mhwe4bJQ2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Enter quast folder\n","%cd quast_results\n","!cp results*/report.html ."],"metadata":{"id":"tyLtOA6rcggP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["3. Now we will look at the report file from our quast run"],"metadata":{"id":"I_RDMCprY5Fk"}},{"cell_type":"code","source":["#@markdown ### Load HTML file from quast\n","html_filename = \"report.html\" #@param {type:\"string\"}\n","#@markdown - This script assumes the HTML file is located in the current folder\n","\n","print('\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n')\n","import IPython\n","IPython.display.HTML(filename=html_filename)"],"metadata":{"cellView":"form","id":"C2qCsDOtbi9L"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Part III - Metagenome binning using metaWRAP"],"metadata":{"id":"RZVnjxfAZDGb"}},{"cell_type":"markdown","source":["1. The binning process is done in two steps. First, the binning is performed over the reads independently with three different software (`--metabat2 --maxbin2 –concoct`) and using the assembly (`-a`). The second step is the joining process of the results from the three binning softwares, and retaining only the mags with > 50 % completeness and < 10 % contamination (`-c 50 -x 10`)"],"metadata":{"id":"fROFCaJTZKdi"}},{"cell_type":"code","source":["#Go back to original folder of the SRA\n","%cd /content/{SRA}"],"metadata":{"id":"6JHoRrgsdYZd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%time\n","%%bash\n","#Now we will activate our conda environment for metaWRAP\n","source activate mwrap-env\n","#We set up this accession ID as a variable\n","SRA=SRR2239652\n","#We will perform binning using metaWRAP with 2 threads\n","#This is sub-optimal, due to Google Colab limitations\n","metawrap binning -o 04_binning_mw -t 2 -a ./03_assembly_msp/contigs.fasta --metabat2 --maxbin2 --concoct ./02_clean_reads/t$SRA\\_1.fastq ./02_clean_reads/t$SRA\\_2.fastq"],"metadata":{"id":"CCrs5G65drsa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["2. Then, the final MAGs are copied to a definite folder in which the names of the files are also automatically changed with the respective scripts. We recommend to further refine MAGs with other software like **refine** or **MAGpurify** to remove inconsistent contigs regarding sequence or taxonomical properties. "],"metadata":{"id":"98lI9u1sZiEQ"}},{"cell_type":"code","source":["#Go back to original folder of the SRA\n","%cd /content/{SRA}\n","!mkdir 06_MAGs_refinement1"],"metadata":{"id":"Wt_-s5ZFZpWo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!cp 04_binning_mw/metabat2_bins/* 06_MAGs_refinement1/\n","%cd 06_MAGs_refinement1/\n","!for f in bin*; do mv \"$f\" \"${f/bin/MAG_{SRA}_}\";done\n","!for f in *.fa; do mv \"$f\" \"${f/.fa/.fasta}\";done"],"metadata":{"id":"wngRtuKnZqxg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Part IV - Predicting and quantifying proteins from metagenomes"],"metadata":{"id":"N33CiyOLaFCB"}},{"cell_type":"markdown","source":["1. From the contigs (or also the MAGs), the protein sequences are predicted with the **Prodigal** software in which the outputs will be a file in genbank format (\\*.gbk), the amino acid sequences with `-a` option (\\*.faa) and the nucleotide sequences of the coding regions with `-d` option (\\*.ffn)."],"metadata":{"id":"4CZRwKeJaKSv"}},{"cell_type":"code","source":["#Go back to original folder of the SRA and create new folder\n","%cd /content/{SRA}\n","!mkdir 07_metaprodigal\n","%cd 07_metaprodigal"],"metadata":{"id":"B6zcA0eerlGN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%time\n","!prodigal -i ../03_assembly_msp/contigs.fasta -p meta -o {SRA}.gbk -a {SRA}.faa -d {SRA}.ffn"],"metadata":{"id":"06oyHrG6rveD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["2. To quantify the number of reads that map to the respective MAGs the software **coverM** will be used. In genome mode, the MAGs can be quantified indicating the folder (`-d`), using the **bwa-mem** mapping software (`-p bwa-mem`) and using the parameter to filter the mapping reads as minimum percent of identity of 95 % and minimum of read alignment of 80 % (`--min-read-percent-identity 95 --min-read-aligned-percent 80`). The software can calculate several metrics, like **relative abundance** for MAGs (`-m relative_abundance`) or **transcripts per million** (TPM; `-m tpm`) for coding sequences. "],"metadata":{"id":"8dqerRmzajed"}},{"cell_type":"code","source":["#Go back to original folder of the SRA and create new folder\n","%cd /content/{SRA}\n","!mkdir 08_quantify\n","%cd 08_quantify"],"metadata":{"id":"TQM6gV24s-j2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%time\n","!coverm genome -1 ../02_clean_reads/t{SRA}_1.fastq -2 ../02_clean_reads/t{SRA}_2.fastq -d ../06_MAGs_refinement1/ -p bwa-mem  --min-read-percent-identity 95 --min-read-aligned-percent 80 -m relative_abundance  --output-file {SRA}_mags_rel_abund --bam-file-cache-directory bam_95_80 -t 2\n","!coverm contig -1 ../02_clean_reads/t{SRA}_1.fastq -2 ../02_clean_reads/t{SRA}_2.fastq -r  ../07_metaprodigal/{SRA}.ffn -p bwa-mem -m tpm --min-read-percent-identity 95 --min-read-aligned-percent 50 -o {SRA}_all_prot_tpm"],"metadata":{"id":"linMXHpwtRUm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["3. The METABOLIC-G software can identify 160 KOFAM profiles related with the main metabolic pathways and biogeochemical cycles, as well the CAZymes and other functions. This can be done over the predicted proteins (`-in`) or over directly on the assembly or the MAGs (`-in-gn`).\n","\n","  The METABOLIC-C version can determine the taxonomy, abundance and cycles of the metagenomes when the reads are also provided and the GTDB-tk software is used.\n","\n","### ⚠️ **CAUTION**: Beware that running metabolic might take a loooong time."],"metadata":{"id":"jgLEtlz9bMn0"}},{"cell_type":"code","source":["#Go back to original folder of the SRA and create new folder\n","%cd /content/{SRA}\n","!mkdir 09_metabolic\n","%cd 09_metabolic"],"metadata":{"id":"mSyQT3vqwUrp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%time\n","%%bash\n","#Now we will activate our conda environment for metabolic\n","source activate metabolic-env \n","#Running metabolic\n","METABOLIC-G.pl -in ../07_metaprodigal/ -o metabolic_all_proteins\n","METABOLIC-G.pl -in-gn ../06_MAGs_refinement1/ -o metabolic_mags"],"metadata":{"id":"o-HwyJb8xE2x"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["4. With all of this, from a metagenome can be characterized the MAGs, the proteins, and their functions as well their abundances. This information will be useful to determine possible roles of microorganisms and their proteins in the environment. Moreover, these insights are the base to study these proteins in silico and in vitro in the laboratory to determine their biotechnological potential and optimization. "],"metadata":{"id":"l6B8cGfDx-pz"}},{"cell_type":"markdown","source":["# Part V - Backing up your files\n","\n","1. This tutorial generated very heavy documents, so you must transfer the files directly to your Google Drive as shown below"],"metadata":{"id":"ibEBKJYicX9b"}},{"cell_type":"code","source":["#Compressing all files into a .tar.gz file\n","%cd /content/\n","!tar -czf D1-tutorial-02.tar.gz *"],"metadata":{"id":"2IKxY5vacyQh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"Li_FWYfTc9a5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import shutil\n","from pathlib import Path \n","backup = Path(\"/content/drive/MyDrive/saocarlos2022/\")\n","if os.path.exists(backup):\n","  print(\"Sao Carlos Workshop 2022 - Backup folder already exists\")\n","if not os.path.exists(backup):\n","  os.mkdir(backup)\n","  print(\"Sao Carlos Workshop 2022 - Backup folder did not exists and was succesfully created\")\n","\n","#Backing up\n","shutil.copy(str('/content/D1-tutorial-02.tar.gz'), str(backup/'D1-tutorial-02.tar.gz'))\n","print(\"Day 1 - Tutorial 2 files successfully backed up!\")"],"metadata":{"id":"a2zqLVXgck50"},"execution_count":null,"outputs":[]}]}