{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrWazTVfeHMf"
      },
      "source": [
        "# Day 2 ‚Äì Tutorial 01:¬†Phylogenetic Analysis using biopython and RAxML"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IA9WmdJLeQRm"
      },
      "source": [
        "## Theoretical Aspects "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spFpaC5lenug"
      },
      "source": [
        "Phylogenetic analysis lies at the core of genomics and bioinformatics and seeks to establish the evolutionary relationships between different homologous DNA or protein sequences and their ancestral sequences (common ancestors) from which they emerge. A typical result from a phylogenetic analysis is a **phylogenetic tree**, such as the following:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gh6BAOK51POj"
      },
      "source": [
        "<figure>\n",
        "<center>\n",
        "<img src='https://raw.githubusercontent.com/pb3lab/ibm3202/master/images/phylo_01.png' width=500/>\n",
        "<figcaption>FIGURE 1. A phylogenetic tree visually represents a hypothesis of how a group of sequences\n",
        "are related. This figure explores how the way a tree is drawn conveys information. This tree shows how the seven sequences at the tips of the branches, called taxa, are related. Each horizontal branch represents an evolutionary\n",
        "lineage. The length of the branch is arbitrary\n",
        "unless the diagram specifies that branch lengths\n",
        "represent information such as time or amount of\n",
        "genetic change. Each branch point represents the common ancestor of the evolutionary lineages diverging from it. One of these branch points represents the common ancestor of all the sequences shown in this tree.\n",
        "<br>Urry LA et al (2020). Campbell Biology. <i>Pearson Education, 12th Ed</i></figcaption></center>\n",
        "</figure>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lrMsCuYTe8Us"
      },
      "source": [
        "In this representation, the tips of the tree (or the leaves) correspond to different, currently existing sequences of genes or proteins (usually called the **taxa**), thus they represent real data. The **nodes** or branch points connecting two sequences are the points of divergence in sequence evolution, namely **common ancestors** of extant taxa. The connection of two or more sequences with a hypothetical, extinct ancestral sequence allows grouping actual sequences into **clades**. On the other hand, the branch lengths represent the evolutionary changes between an ancestor and its descendant. Please note that we are saying **'sequences'** and not **'species'**, as such statement requires the assumption of genetic isolation (i.e. all sequences in a given species show the same evolutionary drifts, but we learn from lectures that we can have horizontal gene transfer, right?)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-dQoKNt5fNFO"
      },
      "source": [
        "Many things can be said about this tree. First, a **phylogenetic tree** is based on a multiple sequence alignment and thus it is **as good as the alignment is**. See for example the polytomy in the ancestral node connecting taxa D, E and F; the sequence information between these sequences did not allow discerning how these sequences evolved from a common ancestor (i.e. imagine that there were two mutations and the phylogenetic analysis does not know which one comes first or second).\n",
        "\n",
        "Second, taxon G is defined as a **basal taxon**, a lineage that diverges from all other members of its group early in the history of the group.\n",
        "\n",
        "Lastly, the phylogenetic tree is **rooted** through an **outgroup**, i.e. a sequence (or a group or sequences) that is more distantly related to the ingroup sequences than the ingroup sequences are to each other; a distant homolog. As an outgroup sequence is not easy to define for all phylogenetic inferences, a vast number of phylogenetic trees in the literature are **unrooted** (i.e. there is no outgroup)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMLCidtMfd7E"
      },
      "source": [
        "A phylogenetic tree is an estimation of the possible routes of evolution from ancestral lineages to present-day sequences that depends on many variables. We will smoothly go through all the steps of this inference, from sequence alignment to the ‚Äúresurrection‚Äù of the most probable ancestral sequence."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_sRCGKuf8Bf"
      },
      "source": [
        "## Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMdhm8X_f_XN"
      },
      "source": [
        "In this tutorial we will work with the family of forkhead box (Fox) transcription factors, a protein family that we currently study [Medina E et al (2016) [*Biophys J 110 (11), 2349-2360*](http://dx.doi.org/10.1016/j.bpj.2016.04.043); Medina E et (2020) [*J Mol Biol 432(19), 5411-5429*](http://dx.doi.org/10.1016/j.jmb.2020.07.017)] as part of a collaboration between the [Protein Biophysics, Biochemistry and Bioinformatics Lab](https://pb3.sitios.ing.uc.cl) from Pontificia Universidad Cat√≥lica de Chile with the [Biochemistry and Molecular Biology Lab](https://sites.google.com/view/labbq) from Universidad de Chile.\n",
        "\n",
        "These proteins are master controllers of gene expression in several eukaryotes since early *Bilateria*, and recently it has been determined that they also participate in chromosome remodeling since their structure is similar to the structure of histones. In humans, there are 19 different Fox subfamilies (from A to S), with almost all of them corresponding to monomeric proteins, except for FoxP. The members of the FoxP subfamily are known to form dimers to allow forming long-distance chromosome interactions due to a key Pro-to-Ala mutation in their sequence (see below)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHm2i0I071U3"
      },
      "source": [
        "<figure>\n",
        "<center>\n",
        "<img src='https://raw.githubusercontent.com/pb3lab/ibm3202/master/images/phylo_02.png'/>\n",
        "<figcaption>FIGURE 2. Sequence determinants of the structural acrobatics of the DNA-binding domain of human FoxP transcription factors. The left panel shows how FoxP proteins oligomerize by exchanging identical secondary structure elements between adjacent subunits, a mechanism known as domain swapping. An experimentally validated key Ala residue that enables domain swapping is indicated, which has been demonstrated to be conserved in all human FoxP proteins and replaced by Pro in all monomeric Fox members, as shown in the multiple sequence alignment on the right.\n",
        "<br> Medina E et al (2016) <i>Biophys J 110 (11), 2349-2360</i>; Stroud JC et al (2008) <i>Structure 14(1), 159-66</i></figcaption></center>\n",
        "</figure>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QLCIaTFBgTcY"
      },
      "source": [
        "Today, we will infer where did the evolutionary novelty of forming dimers emerged during the\n",
        "evolution of Fox proteins using **RAxML** (Randomized Axelerated Maximum Likelihood), a popular program for phylogenetic analyses of large datasets under maximum likelihood."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "buTRd47h4QfK"
      },
      "source": [
        "#Part 0. Downloading and Installing the required software"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KSAoowL_4XIV"
      },
      "source": [
        "Before we start, you must first **remember to start the hosted runtime in Google Colab**.\n",
        "\n",
        "Then, we must install several pieces of software to perform this tutorial. Namely:\n",
        "- **biopython** for searching, retrieving, parsing and storing DNA and protein sequences.\n",
        "- **miniconda**, a free minimal installer of **conda** for software package and environment management.\n",
        "- **MAFFT**, a multiple sequence alignment program for unix-like operating systems that offers a range of multiple alignment methods.\n",
        "- **ModelTest-ng**, a tool for selecting the best-fit model of evolution for DNA and protein alignments.\n",
        "- **RAxML-ng**, a phylogenetic tree inference tool which uses maximum-likelihood (ML) optimality criterion.\n",
        "\n",
        "After several tests, the following installation instructions are the best way of setting up **Google Colab** for this laboratory session.\n",
        "\n",
        "1. We will first install **biopython** as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PdWvUiMR38gO"
      },
      "source": [
        "#Installing biopython using pip\n",
        "!pip install biopython"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3NwRC9A58AN"
      },
      "source": [
        "#Importing biopython and os for safety\n",
        "import os\n",
        "import sys\n",
        "import Bio"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Goex7fGQTmcR"
      },
      "source": [
        "2. Finally, we will install conda to be able to install **mafft**, **cd-hit**, **RAxML-NG** and **ModelTest-NG** as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7x5g0HGxwpB"
      },
      "source": [
        "#Install conda using the new conda-colab library\n",
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install_miniconda()\n",
        "\n",
        "#Install RAxML-NG and ModelTest-NG from\n",
        "#the bioconda repository\n",
        "!conda install -c bioconda raxml-ng modeltest-ng mafft cd-hit --yes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚ö†Ô∏è **WARNING**: After installation of condacolab, the runtime session will crash. This is a normal behaviour, but it prevents to automatically execute all other cell codes after installation (`Runtime -> Run all` will not work)."
      ],
      "metadata": {
        "id": "1RKIanOM1ciL"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4da3gT4hlfd"
      },
      "source": [
        "#Part I - Retrieve Fox protein sequences using BLAST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uysnl6lrW2rb"
      },
      "source": [
        "Biopython is an excellent companion for working with DNA and protein sequences and also with structures. Here, we will show how to use it for retrieving Fox protein sequences using BLAST directly into Google Colab.\n",
        "\n",
        "1. First, we will start by using _Entrez_ to retrieve the sequence of accession code **2KIU_A** in FASTA format and _SeqIO_ to be able to read, parse and/or write this sequence. Besides downloading our sequence, we will also store the sequence into a string (here, termed as _aaseq_) for its subsequent use in this tutorial."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vt1ke8upXSl9"
      },
      "source": [
        "from Bio import SeqIO, Entrez\n",
        "#Setting up your email to be able to use Entrez\n",
        "Entrez.email = 'your.email@uc.cl'\n",
        "#Here, we set up a temporary handle with our downloaded sequence in fasta format\n",
        "temp = Entrez.efetch(db=\"protein\",rettype=\"fasta\",id=\"2KIU_A\")\n",
        "#Creating a fasta file to write our downloaded sequence\n",
        "aaseq_out = open(\"2KIU_A.fasta\",'w')\n",
        "#Reading the sequence information as a string in fasta format\n",
        "aaseq = SeqIO.read(temp, format=\"fasta\")\n",
        "#Writing the sequence record in fasta format\n",
        "SeqIO.write(aaseq,aaseq_out,\"fasta\")\n",
        "#Closing both the temp handle and the FASTA file\n",
        "temp.close()\n",
        "aaseq_out.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "klOzI65TXfJ6"
      },
      "source": [
        "2. What is great about _SeqIO_ is that you can use it to manipulate your sequence (e.g. sorting, changing formats, etc) and also to print information about your sequence, such as its description, sequence and accession ID.\n",
        "\n",
        "  You can try these commands below by first writing **\"aaseq.\"** and then selecting one of the autocomplete options suggested by Google Colab, as exemplified below for getting the sequence of the protein"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gy8YLQM3Z151"
      },
      "source": [
        "#Printing the number of amino acids as an example\n",
        "print(\"Amino acid sequence:\")\n",
        "print(aaseq.seq)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bQo87E1lmfR"
      },
      "source": [
        "**üí° HINT:** If you are working with a protein/nucleic sequence of your own instead of an accession ID, you can store the sequence in a string using the _**Seq**_ function as shown below:\n",
        "\n",
        "\n",
        "\n",
        "> ```from Bio.Seq import Seq\n",
        "my_seq = Seq(\"AEVRPPFTYASLIRQAILESPEKQLTLNEIYNWFTRMFPYFRRNAATWKNAVRHNLSLHKYFVRVENVKGAVWTVDEVEFQKRRPQK\")```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HnVcH7l4izF2"
      },
      "source": [
        "3. Once we have already stored the information of our query sequence in a string, we can use it to perform a BLAST search inside Google Colab via biopython through _NCBIWWW_.\n",
        "\n",
        "  The code cell bellow specifies the blast program **blastp**, the database **pdb** and the query sequence. This process should not take longer than 2 min."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChxitIMEkw8E"
      },
      "source": [
        "#Using biopython to perform a blast search\n",
        "%%time\n",
        "from Bio.Blast import NCBIWWW\n",
        "#NCBIWWW.qblast(program, database, sequence)\n",
        "result_handle = NCBIWWW.qblast(\"blastp\", \"pdb\", aaseq.seq, entrez_query='human[organism]')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "al-iSDTlk02T"
      },
      "source": [
        "**üí° HINT:** Please note that we are using the PDB protein database only for the purposes of this tutorial, as it has a limited number of protein sequences (due to the limited number of structures). However, you might find the use of another database more suitable for your work with your own protein or DNA sequences, as they contain a higher number of sequences, hence a higher sequence variability/redundancy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DC3IwSuimbaW"
      },
      "source": [
        "4. In order to parse this data, we need to store it in a handle for post-processing using _NCBIXML_, as shown below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZozLVEcnfA1"
      },
      "source": [
        "#Read the results in XML format for parsing BLAST records\n",
        "from Bio.Blast import NCBIXML\n",
        "blast_record = NCBIXML.read(result_handle)\n",
        "#This is required to reset the searches and start over again\n",
        "result_handle.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VvWpHiceqNi5"
      },
      "source": [
        "5. We can now use all the functions in Bio.Blast to print a BLAST-like briefing of the results, and to even filter the results according to parameters such as the sequence identity, coverage and/or e-value. **Carefully examine the commands executed below to achieve this task.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atHlk0A-iRtZ"
      },
      "source": [
        "#Here, we show how we can set a sequence identity cut-off\n",
        "#Many other cut-offs can be employed!\n",
        "PIDcut=1.00\n",
        "#Printing all BLAST parameters similarly to the website\n",
        "for alignment in blast_record.alignments:\n",
        "  for hsp in alignment.hsps:\n",
        "#Here, we add a condition to only print hits equal or less than a PID cutoff\n",
        "    if(hsp.identities/hsp.align_length) <= PIDcut:\n",
        "      print(\"Accession code:\", alignment.hit_id)\n",
        "      print(\"Sequence length:\", alignment.length)\n",
        "      print(\"Alignment length:\", hsp.align_length)\n",
        "      print(\"E-value:\", hsp.expect)\n",
        "#The following command calculates the sequence identity relative to\n",
        "#the length of the alignment\n",
        "      print(\"Sequence Identity [%]:\", \"{:.2f}\".format(100*hsp.identities/hsp.align_length))\n",
        "#The following command calculates the sequence coverage relative to\n",
        "#the lenght of the sequence\n",
        "      print(\"Sequence Coverage [%]:\", \"{:.2f}\".format(100*sum(c.isalpha() for c in hsp.query)/len(aaseq)))\n",
        "      print()\n",
        "#Here, we print the first 60 characters of the query and hit and their matches\n",
        "      print(\"query:\", hsp.query[0:60] + \"...\")\n",
        "      print(\"      \", hsp.match[0:60] + \"...\")\n",
        "      print(\"sbjct:\", hsp.sbjct[0:60] + \"...\")\n",
        "      print()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cKEj6ApscwF"
      },
      "source": [
        "**üìö HOMEWORK:** Copy the code cell above and play around with it to add other filters instead of PID, such as a minimum E-value or sequence coverage."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9IwBZmXOtmc5"
      },
      "source": [
        "6. After the BLAST search and filtering, we would like to retrieve all sequences that match our selection criteria. Here, we opted to download the top 20 sequences, but you can use filters such as minimum sequence coverage, minimum e-value and maximum PID to limit your output sequences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWaDVmpp3JDx"
      },
      "source": [
        "#Setting up your email to be able to use Entrez\n",
        "Entrez.email = 'your.email@uc.cl'\n",
        "\n",
        "#Generate a loop to write all sequences into an output file\n",
        "with open(\"sequences.fasta\", \"a\") as allhits_out:\n",
        "#Check how we are indicating to use the top 20 hits\n",
        "  for alignment in blast_record.alignments[:20]:\n",
        "    for hsp in alignment.hsps:\n",
        "    #Here, we add a condition to print only sequences below a PID cutoff\n",
        "      if(hsp.identities/len(hsp.match)) <= PIDcut:\n",
        "        print(\"Fetching protein sequence:\", alignment.hit_id)\n",
        "        fetch = Entrez.efetch(db=\"protein\", id=alignment.hit_id, rettype=\"fasta\")\n",
        "        #Reading the sequence stored in the temporary string in fasta format\n",
        "        allhits_seqs = SeqIO.read(fetch, format=\"fasta\")\n",
        "        #Writing the sequence and its ID in fasta format\n",
        "        SeqIO.write(allhits_seqs,allhits_out,\"fasta\")\n",
        "        fetch.close()\n",
        "#Closing the efetch and file\n",
        "allhits_out.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7a8lnCG8xkEx"
      },
      "source": [
        "üò± **EMERGENCY BACKUP!** In case BLASTP fails due to an issue with the NCBI servers, you can download a FASTA file containing 20 protein sequence homologs generated on Oct 9, 2022:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WWm3QqTyFgW"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/pb3lab/workshops/main/backups/saocarlos2022/D2-T1_sequences.fasta -O sequences.fasta"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9h_NN5COWGjo"
      },
      "source": [
        "#Part II - Obtain and edit a Multiple Sequence Alignment (MSA) using MAFFT and biopython"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bEM7r3aL87xu"
      },
      "source": [
        "Once BLAST is resolved, we can proceeed with the **Multiple Sequence Alignment (MSA)**. In this case, we will first employ **MAFFT** to align all retrieved sequences.\n",
        "\n",
        "1. To perform a MSA alignment using MAFFT, we can again use the biopython _Bio.Align.Applications_ wrapper as shown in the code cell below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ql6daJM9bMuS"
      },
      "source": [
        "from Bio.Align.Applications import MafftCommandline\n",
        "mafft_cline=MafftCommandline(input=\"sequences.fasta\")\n",
        "print(mafft_cline)\n",
        "stdout, stderr = mafft_cline()\n",
        "with open(\"aligned.fasta\", \"w\") as handle:\n",
        "  handle.write(stdout)\n",
        "from Bio import AlignIO\n",
        "align = AlignIO.read(\"aligned.fasta\", \"fasta\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_wbJAK9-Bku"
      },
      "source": [
        "2. The result from this algorithm, which is an extension of the **Pairwise Alignment Algorithms** we discussed during Lectures, can be seen in an online MSA viewer such as [Alignment Viewer 2.0](https://fast.alignmentviewer.org/) or using the form below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "UYrebWipbp5A"
      },
      "source": [
        "#@title Protein MSA Viewer in Google Colab\n",
        "#The following code is modified from the wonderful viewer developed by Damien Farrell\n",
        "#https://dmnfarrell.github.io/bioinformatics/bokeh-sequence-aligner\n",
        "\n",
        "#Importing all modules first\n",
        "import os, io, random\n",
        "import string\n",
        "import numpy as np\n",
        "\n",
        "from Bio.Seq import Seq\n",
        "from Bio.Align import MultipleSeqAlignment\n",
        "from Bio import AlignIO, SeqIO\n",
        "\n",
        "import panel as pn\n",
        "import panel.widgets as pnw\n",
        "pn.extension()\n",
        "\n",
        "from bokeh.plotting import figure\n",
        "from bokeh.models import ColumnDataSource, Plot, Grid, Range1d\n",
        "from bokeh.models.glyphs import Text, Rect\n",
        "from bokeh.layouts import gridplot\n",
        "\n",
        "#Setting up the amino color code according to Zappo color scheme\n",
        "def get_colors(seqs):\n",
        "    #make colors for bases in sequence\n",
        "    text = [i for s in list(seqs) for i in s]\n",
        "    #Use Zappo color scheme\n",
        "    clrs =  {'K':'red',\n",
        "             'R':'red',\n",
        "             'H':'red',             \n",
        "             'D':'green',\n",
        "             'E':'green',\n",
        "             'Q':'blue',\n",
        "             'N':'blue',\n",
        "             'S':'blue',\n",
        "             'T':'blue',\n",
        "             'A':'blue',\n",
        "             'I':'blue',\n",
        "             'L':'blue',\n",
        "             'M':'blue',\n",
        "             'V':'blue',\n",
        "             'F':'orange',\n",
        "             'Y':'orange',\n",
        "             'W':'orange',\n",
        "             'C':'blue',\n",
        "             'P':'yellow',\n",
        "             'G':'orange',\n",
        "             '-':'white'}\n",
        "    colors = [clrs[i] for i in text]\n",
        "    return colors\n",
        "\n",
        "#Setting up the MSA viewer\n",
        "def view_alignment(aln, fontsize=\"9pt\", plot_width=800):\n",
        "    \"\"\"Bokeh sequence alignment view\"\"\"\n",
        "\n",
        "    #make sequence and id lists from the aln object\n",
        "    seqs = [rec.seq for rec in (aln)]\n",
        "    ids = [rec.id for rec in aln]    \n",
        "    text = [i for s in list(seqs) for i in s]\n",
        "    colors = get_colors(seqs)    \n",
        "    N = len(seqs[0])\n",
        "    S = len(seqs)    \n",
        "    width = .4\n",
        "\n",
        "    x = np.arange(1,N+1)\n",
        "    y = np.arange(0,S,1)\n",
        "    #creates a 2D grid of coords from the 1D arrays\n",
        "    xx, yy = np.meshgrid(x, y)\n",
        "    #flattens the arrays\n",
        "    gx = xx.ravel()\n",
        "    gy = yy.flatten()\n",
        "    #use recty for rect coords with an offset\n",
        "    recty = gy+.5\n",
        "    h= 1/S\n",
        "    #now we can create the ColumnDataSource with all the arrays\n",
        "    source = ColumnDataSource(dict(x=gx, y=gy, recty=recty, text=text, colors=colors))\n",
        "    plot_height = len(seqs)*15+50\n",
        "    x_range = Range1d(0,N+1, bounds='auto')\n",
        "    if N>100:\n",
        "        viewlen=100\n",
        "    else:\n",
        "        viewlen=N\n",
        "    #view_range is for the close up view\n",
        "    view_range = (0,viewlen)\n",
        "    tools=\"xpan, xwheel_zoom, reset, save\"\n",
        "\n",
        "    #entire sequence view (no text, with zoom)\n",
        "    p = figure(title=None, plot_width= plot_width, plot_height=50,\n",
        "               x_range=x_range, y_range=(0,S), tools=tools,\n",
        "               min_border=0, toolbar_location='below')\n",
        "    rects = Rect(x=\"x\", y=\"recty\",  width=1, height=1, fill_color=\"colors\",\n",
        "                 line_color=None, fill_alpha=0.6)\n",
        "    p.add_glyph(source, rects)\n",
        "    p.yaxis.visible = False\n",
        "    p.grid.visible = False  \n",
        "\n",
        "    #sequence text view with ability to scroll along x axis\n",
        "    p1 = figure(title=None, plot_width=plot_width, plot_height=plot_height,\n",
        "                x_range=view_range, y_range=ids, tools=\"xpan,reset\",\n",
        "                min_border=0, toolbar_location='below')#, lod_factor=1)          \n",
        "    glyph = Text(x=\"x\", y=\"y\", text=\"text\", text_align='center',text_color=\"black\",\n",
        "                text_font=\"monospace\",text_font_size=fontsize)\n",
        "    rects = Rect(x=\"x\", y=\"recty\",  width=1, height=1, fill_color=\"colors\",\n",
        "                line_color=None, fill_alpha=0.4)\n",
        "    p1.add_glyph(source, glyph)\n",
        "    p1.add_glyph(source, rects)\n",
        "\n",
        "    p1.grid.visible = False\n",
        "    p1.xaxis.major_label_text_font_style = \"bold\"\n",
        "    p1.yaxis.minor_tick_line_width = 0\n",
        "    p1.yaxis.major_tick_line_width = 0\n",
        "\n",
        "    p = gridplot([[p],[p1]], toolbar_location='below')\n",
        "    return p\n",
        "\n",
        "#Loading the viewer by indicating the MSA file and format to read\n",
        "#@markdown Name of the MSA file (including the file extension)\n",
        "MSAfile = 'aligned.fasta' #@param {type:\"string\"}\n",
        "MSAformat = 'fasta' #@param {type:\"string\"}\n",
        "aln = AlignIO.read(MSAfile,MSAformat)\n",
        "p = view_alignment(aln, plot_width=900)\n",
        "pn.pane.Bokeh(p)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exUsc7YR-dXe"
      },
      "source": [
        "3. As you can see, the sequences are aligned, as many residues that are conserved between different sequences occupy the same columns within the alignment. However, **we can also see\n",
        "some sequences that are longer on the ends of the protein**. These ends will contribute nothing to the alignment, as there is nothing to compare them to. Therefore, we will trim the sequences on both N-and C-ends by selecting the regions we want to eliminate.\n",
        "\n",
        "  Due to time restrictions, we include a script below that trims the N- and C-ends of the alignment based on finding the first and lasts columns of the MSA without any gaps.\n",
        "\n",
        "**üí° HINT:** Ideally, you would manually correct the alignment and trim the ends of the sequences after careful inspection, which **we encourage you to do in real cases**.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPgR1wuGzHWL"
      },
      "source": [
        "import sys\n",
        "from Bio import AlignIO\n",
        "aln = AlignIO.read(\"aligned.fasta\", \"fasta\")\n",
        "\n",
        "for fcol in range(aln.get_alignment_length()):\n",
        "  if not \"-\" in aln[:, fcol]:\n",
        "    position1 = fcol\n",
        "    print(\"First full column is {}\".format(fcol))\n",
        "    break\n",
        "for lcol in reversed(range(aln.get_alignment_length())):\n",
        "  if not \"-\" in aln[:, lcol]:\n",
        "    position2 = lcol+1\n",
        "    print(\"Last full column is {}\".format(lcol))\n",
        "    break\n",
        "\n",
        "print(\"New alignment:\")\n",
        "print(aln[:, position1:position2])\n",
        "\n",
        "with open(\"aligned_trimmed.fasta\", \"w\") as handle:\n",
        "  count = (SeqIO.write(aln[:, position1:position2], handle, \"fasta\"))\n",
        "\n",
        "trim = AlignIO.read(\"aligned_trimmed.fasta\", \"fasta\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwIFOU8L_rAg"
      },
      "source": [
        "4. We also need to **make sure that there are no duplicated sequences included in it**. Having redundant information does not have any benefit for the phylogenetic analysis that we are pursuing here.\n",
        "\n",
        "  A suitable programs to eliminate duplicated in our alignment is **CD-HIT**, which we will employ below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xm7b8rCAAC8O"
      },
      "source": [
        "#cd-hit only reads ungapped, single-line fasta, which is why we convert\n",
        "#our file first using biopython as shown below\n",
        "from Bio.Seq import Seq\n",
        "from Bio import SeqIO\n",
        "with open(\"file_for_cdhit.fasta\", \"w\") as o:\n",
        "    for record in SeqIO.parse(\"aligned_trimmed.fasta\", \"fasta\"):\n",
        "        record.seq = record.seq.ungap(\"-\")\n",
        "        SeqIO.write(record, o, \"fasta-2line\")\n",
        "\n",
        "#Now we use cd-hit\n",
        "!cd-hit -i file_for_cdhit.fasta -o cdhit_nodup.fasta -c 1.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**üí° HINT:** Note that we are using `-c 1.0`, where 1.0 refers to 100% PID, to only eliminate duplicates. However, you could cluster your sequences to lower PID if required (e.g. you have too many sequences that are highly similar to each other).\n"
      ],
      "metadata": {
        "id": "v9GWlwP1TFnz"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSIIvNPzAktp"
      },
      "source": [
        "5. We will generate again a multiple sequence alignment using our filtered sequences and visually inspect it."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from Bio.Align.Applications import MafftCommandline\n",
        "mafft_cline=MafftCommandline(input=\"cdhit_nodup.fasta\")\n",
        "print(mafft_cline)\n",
        "stdout, stderr = mafft_cline()\n",
        "with open(\"aligned_trimmed_final.fasta\", \"w\") as handle:\n",
        "  handle.write(stdout)\n",
        "from Bio import AlignIO\n",
        "align = AlignIO.read(\"aligned_trimmed_final.fasta\", \"fasta\")"
      ],
      "metadata": {
        "id": "IyyxCvT1e3Qx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "KGnHXeHAgQi_"
      },
      "source": [
        "#@title Protein MSA Viewer in Google Colab\n",
        "#The following code is modified from the wonderful viewer developed by Damien Farrell\n",
        "#https://dmnfarrell.github.io/bioinformatics/bokeh-sequence-aligner\n",
        "\n",
        "#Importing all modules first\n",
        "import os, io, random\n",
        "import string\n",
        "import numpy as np\n",
        "\n",
        "from Bio.Seq import Seq\n",
        "from Bio.Align import MultipleSeqAlignment\n",
        "from Bio import AlignIO, SeqIO\n",
        "\n",
        "import panel as pn\n",
        "import panel.widgets as pnw\n",
        "pn.extension()\n",
        "\n",
        "from bokeh.plotting import figure\n",
        "from bokeh.models import ColumnDataSource, Plot, Grid, Range1d\n",
        "from bokeh.models.glyphs import Text, Rect\n",
        "from bokeh.layouts import gridplot\n",
        "\n",
        "#Setting up the amino color code according to Zappo color scheme\n",
        "def get_colors(seqs):\n",
        "    #make colors for bases in sequence\n",
        "    text = [i for s in list(seqs) for i in s]\n",
        "    #Use Zappo color scheme\n",
        "    clrs =  {'K':'red',\n",
        "             'R':'red',\n",
        "             'H':'red',             \n",
        "             'D':'green',\n",
        "             'E':'green',\n",
        "             'Q':'blue',\n",
        "             'N':'blue',\n",
        "             'S':'blue',\n",
        "             'T':'blue',\n",
        "             'A':'blue',\n",
        "             'I':'blue',\n",
        "             'L':'blue',\n",
        "             'M':'blue',\n",
        "             'V':'blue',\n",
        "             'F':'orange',\n",
        "             'Y':'orange',\n",
        "             'W':'orange',\n",
        "             'C':'blue',\n",
        "             'P':'yellow',\n",
        "             'G':'orange',\n",
        "             '-':'white'}\n",
        "    colors = [clrs[i] for i in text]\n",
        "    return colors\n",
        "\n",
        "#Setting up the MSA viewer\n",
        "def view_alignment(aln, fontsize=\"9pt\", plot_width=800):\n",
        "    \"\"\"Bokeh sequence alignment view\"\"\"\n",
        "\n",
        "    #make sequence and id lists from the aln object\n",
        "    seqs = [rec.seq for rec in (aln)]\n",
        "    ids = [rec.id for rec in aln]    \n",
        "    text = [i for s in list(seqs) for i in s]\n",
        "    colors = get_colors(seqs)    \n",
        "    N = len(seqs[0])\n",
        "    S = len(seqs)    \n",
        "    width = .4\n",
        "\n",
        "    x = np.arange(1,N+1)\n",
        "    y = np.arange(0,S,1)\n",
        "    #creates a 2D grid of coords from the 1D arrays\n",
        "    xx, yy = np.meshgrid(x, y)\n",
        "    #flattens the arrays\n",
        "    gx = xx.ravel()\n",
        "    gy = yy.flatten()\n",
        "    #use recty for rect coords with an offset\n",
        "    recty = gy+.5\n",
        "    h= 1/S\n",
        "    #now we can create the ColumnDataSource with all the arrays\n",
        "    source = ColumnDataSource(dict(x=gx, y=gy, recty=recty, text=text, colors=colors))\n",
        "    plot_height = len(seqs)*15+50\n",
        "    x_range = Range1d(0,N+1, bounds='auto')\n",
        "    if N>100:\n",
        "        viewlen=100\n",
        "    else:\n",
        "        viewlen=N\n",
        "    #view_range is for the close up view\n",
        "    view_range = (0,viewlen)\n",
        "    tools=\"xpan, xwheel_zoom, reset, save\"\n",
        "\n",
        "    #entire sequence view (no text, with zoom)\n",
        "    p = figure(title=None, plot_width= plot_width, plot_height=50,\n",
        "               x_range=x_range, y_range=(0,S), tools=tools,\n",
        "               min_border=0, toolbar_location='below')\n",
        "    rects = Rect(x=\"x\", y=\"recty\",  width=1, height=1, fill_color=\"colors\",\n",
        "                 line_color=None, fill_alpha=0.6)\n",
        "    p.add_glyph(source, rects)\n",
        "    p.yaxis.visible = False\n",
        "    p.grid.visible = False  \n",
        "\n",
        "    #sequence text view with ability to scroll along x axis\n",
        "    p1 = figure(title=None, plot_width=plot_width, plot_height=plot_height,\n",
        "                x_range=view_range, y_range=ids, tools=\"xpan,reset\",\n",
        "                min_border=0, toolbar_location='below')#, lod_factor=1)          \n",
        "    glyph = Text(x=\"x\", y=\"y\", text=\"text\", text_align='center',text_color=\"black\",\n",
        "                text_font=\"monospace\",text_font_size=fontsize)\n",
        "    rects = Rect(x=\"x\", y=\"recty\",  width=1, height=1, fill_color=\"colors\",\n",
        "                line_color=None, fill_alpha=0.4)\n",
        "    p1.add_glyph(source, glyph)\n",
        "    p1.add_glyph(source, rects)\n",
        "\n",
        "    p1.grid.visible = False\n",
        "    p1.xaxis.major_label_text_font_style = \"bold\"\n",
        "    p1.yaxis.minor_tick_line_width = 0\n",
        "    p1.yaxis.major_tick_line_width = 0\n",
        "\n",
        "    p = gridplot([[p],[p1]], toolbar_location='below')\n",
        "    return p\n",
        "\n",
        "#Loading the viewer by indicating the MSA file and format to read\n",
        "#@markdown Name of the MSA file (including the filetype)\n",
        "MSAfile = 'aligned_trimmed_final.fasta' #@param {type:\"string\"}\n",
        "MSAformat = 'fasta' #@param {type:\"string\"}\n",
        "aln = AlignIO.read(MSAfile,MSAformat)\n",
        "p = view_alignment(aln, plot_width=900)\n",
        "pn.pane.Bokeh(p)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JH1AQWch94m"
      },
      "source": [
        "#Part III - Phylogenetic inference and ancestral sequence reconstruction using RAxML"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9AX2DwfeBs0y"
      },
      "source": [
        "We will use our final, trimmed and filtered alignment to infer the phylogenetic relationships of our sequences with the **heuristic** tree-searching method of **RAxML** using the **Maximum Likelihood (ML)** optimality criterion.\n",
        "\n",
        "While we already discussed about some of the phylogenetic methods as well as evolutionary models during our lecture, we did not discuss about the incorporation of additional parameters, such as **invariant sites** (conservation) or variations in the substitution rates across sites. For example, **initiation codons (typically, ATG)** may not be free to vary at all. Therefore, we should make such sites invariant.\n",
        "\n",
        "  On the other hand, we know that positions on the interior of a protein evolve more slowly that surface residues, therefore substitutions have **varying rates** depending on the position of these residues. In the case of variation, modeling these varying rates is computationally consuming, thus a well-behaved, mathematically tractable **gamma distribution** is used for modeling these rate variations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohAIWzroCvGg"
      },
      "source": [
        "1. Now we will starting doing some ML phylogenetics, but **which model should we use?** Well, ML has the advantage that we can use the **log-likelihood** to infer which evolutionary model is more suitable for the alignment being used. This is implemented in the **ModelTest-NG** program and can be used as follows:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klKC-g6dCKqy"
      },
      "source": [
        "!modeltest-ng -i aligned_trimmed_final.fasta -d aa"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRmZhhB67_ep"
      },
      "source": [
        "The result will look very complex and unreadable. However, the models are selected according to **BIC** and **AICc**, which determine the suitability of a given model if it best-minimize **-lnL**. Here, **lnL** is the log-likelihood, with its negative value used as the minimization target during model selection. **In our particular case, the best model turned out as LG+G4**, or the **Le-Gascuel model** with **Gamma** variation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1eiPJIF90dU"
      },
      "source": [
        "2. Now, we can use our final MSA to perform our first phylogenetic analysis using **RAxML-NG**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHKS7xYHEVh_"
      },
      "source": [
        "#RAxML does not like spaces in the fasta headers\n",
        "#Keeping only IDs here\n",
        "!awk '/^>/ {$0=$1} 1' aligned_trimmed_final.fasta > aligned_trimmed_raxml.fasta\n",
        "\n",
        "#Now we run RAxML\n",
        "!raxml-ng --msa aligned_trimmed_raxml.fasta --model LG+G4 --prefix T1 --threads 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tS0DiOPc-jg7"
      },
      "source": [
        "3. We can again use biopython to see the results of our phylogenetic inference using the _Phylo_ tool."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-elKCfF-s8n"
      },
      "source": [
        "from Bio import Phylo\n",
        "tree = Phylo.read(\"T1.raxml.bestTree\", \"newick\")\n",
        "Phylo.draw(tree)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "llzvGVk8EadP"
      },
      "source": [
        "4. Now we need to test the reliability (reproducibility) of our phylogenetic tree using the **boostrapping method** that we discussed during our Lectures. Remember that this is not part of the tree construction method, but a phylogeny test.\n",
        "\n",
        "  While usually 1000-2000 bootstrap replicates are suggested for determining the confidence of the phylogenetic tree, RAxML also has a so-called **bootstopping** method that determines how many bootstrap replicates are required to obtain stable support values. However, for a speedy tutorial, we have requested 100 boostrap replicates only."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ov41LC47BUNe"
      },
      "source": [
        "!raxml-ng --bootstrap --msa T1.raxml.rba --model LG+G4 --prefix T2 --threads 2 --bs-tree 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKPkOtxjE2ap"
      },
      "source": [
        "**üí° HINT:** You can still check the convergence of the boostrapping test afterwards by executing the command below. In practice, a convergence cutoff value of 3% should be sufficient in most cases.\n",
        "\n",
        "```\n",
        "!raxml-ng --bsconverge --bs-trees T2.raxml.bootstraps --prefix Test --threads 2 --bs-cutoff 0.03\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMWzFYCJCnaR"
      },
      "source": [
        "5. Now, we will map the support values obtained from the boostrapping test onto the best-scoring ML tree on the original MSA. Once you ran the cell code below, use the Phylo package again to show the phylogenetic tree with its bootstrapping values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Rr3dZmWHDVV"
      },
      "source": [
        "!raxml-ng --support --tree T1.raxml.bestTree --bs-trees T2.raxml.bootstraps --prefix T3 --threads 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9uwp7HC7ClwT"
      },
      "source": [
        "from Bio import Phylo\n",
        "tree = Phylo.read(\"T3.raxml.support\", \"newick\")\n",
        "Phylo.draw(tree)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6Q-WDyIH8K9"
      },
      "source": [
        "6. With this, we are done with inferring our phylogenetic trees. Also, we can get and download the **raxml.bestTree** file (which is the tree file) an see it in the visualizing website [**iTOL**](https://itol.embl.de/). \n",
        "\n",
        "  At the top of the iTOL website, there is an **UPLOAD** button. We can press the button and upload the besttree file to nicely draw our phylogenetic tree."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lnl-9luRIgY2"
      },
      "source": [
        "7. We will now **use the ML tree** to obtain an estimation of the **ancestral sequence** for the FoxP clade. Since we already have the MSA and the ML tree, and the ML tree is a result of the probability of each position in the alignment, we do not need anything extra to obtain the ancestral sequences at each of the internal nodes. Just use the code below.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmxWkKnJiLaO"
      },
      "source": [
        "!raxml-ng --ancestral --msa aligned_trimmed_raxml.fasta --tree T1.raxml.bestTree --model LG+G4 --prefix ASR"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7cgzhP-dJN6b"
      },
      "source": [
        "8. Now, we will visualize the resulting **raxml.ancestralTree** file in which the names of each ancestral node in the tree. We will peak one of these nodes to print out its sequence, which is contained in the **raxml.ancestralStates**.\n",
        "\n",
        "  The DNA encoding these protein sequences are usually synthesized by researchers to evaluate their structure and function and allowing inference of the cellular, environmental and functional contexts of ancestral and extant organisms."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBvCa7KGKGEL"
      },
      "source": [
        "#Here, se the biopython Phylo package again!\n",
        "from Bio import Phylo\n",
        "tree = Phylo.read(\"ASR.raxml.ancestralTree\", \"newick\")\n",
        "Phylo.draw(tree)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Here we are printing the sequence of Node12 as our ancestral candidate for further analysis\n",
        "!grep \"Node12\" ASR.raxml.ancestralStates"
      ],
      "metadata": {
        "id": "McDyzPlvCpaO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. It is always required to check that the residue assigned by ML analysis to each position in our ancestral sequence is the most probable one. This per-position information for all nodes is contained in the **raxml.ancestralProbs** file. We are loading this information below using **pandas**."
      ],
      "metadata": {
        "id": "yB89tmRZy99G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read Text Files with Pandas using read_csv()\n",
        "  \n",
        "# importing pandas\n",
        "import pandas as pd\n",
        "\n",
        "# enabling a higher number of columns on Colab\n",
        "from google.colab.data_table import DataTable\n",
        "DataTable.max_columns = 30\n",
        "\n",
        "# read text file into pandas DataFrame\n",
        "df = pd.read_csv(\"ASR.raxml.ancestralProbs\", delim_whitespace=True)\n",
        "  \n",
        "# display DataFrame\n",
        "df"
      ],
      "metadata": {
        "id": "WPtOTvvdMo9k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part IV - Backing up your files\n",
        "\n",
        "1. If you want to download your produced files, execute the code below. A compressed .tar.gz file will be generated and automatically downloaded into your computer (unless you have an ad-blocker, for which you will have to manually download it)."
      ],
      "metadata": {
        "id": "toiYA2orzYox"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Compressing all files into a .tar.gz file\n",
        "!tar -czf D2-tutorial-01.tar.gz *"
      ],
      "metadata": {
        "id": "sH0OhkCm0LNc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"/content/D2-tutorial-01.tar.gz\")"
      ],
      "metadata": {
        "id": "_W_kXHII9Mvq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Alternatively, you can transfer the files directly to your Google Drive as shown below:"
      ],
      "metadata": {
        "id": "q2GaIuJU8EZi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "q5qWqHeb8btw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from pathlib import Path \n",
        "backup = Path(\"/content/drive/MyDrive/saocarlos2022/\")\n",
        "if os.path.exists(backup):\n",
        "  print(\"Sao Carlos Workshop 2022 - Backup folder already exists\")\n",
        "if not os.path.exists(backup):\n",
        "  os.mkdir(backup)\n",
        "  print(\"Sao Carlos Workshop 2022 - Backup folder did not exists and was succesfully created\")\n",
        "\n",
        "#Backing up\n",
        "shutil.copy(str('/content/D2-tutorial-01.tar.gz'), str(backup/'D2-tutorial-01.tar.gz'))\n",
        "print(\"Day 2 - Tutorial 1 files successfully backed up!\")"
      ],
      "metadata": {
        "id": "VtqClLKW8mKn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}